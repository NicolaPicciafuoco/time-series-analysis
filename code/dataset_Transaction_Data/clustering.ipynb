{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c55ac2c",
   "metadata": {},
   "source": [
    "Download the dataset and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a17d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kagglehub\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ba6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"thedevastator/online-retail-transaction-data\")\n",
    "\n",
    "# print the path\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5996dfb",
   "metadata": {},
   "source": [
    "Display the dataset and ETL process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2cd6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path + \"/online_retail.csv\")\n",
    "\n",
    "data.head()\n",
    "#print(\"Info:\") \n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889da873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the total number of rows before cleaning\n",
    "print(f\"Total rows before cleaning: {data.shape[0]}\")\n",
    "\n",
    "# Cleaning the data\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])  # Convert InvoiceDate to datetime\n",
    "data = data[(data['Quantity'] > 0) & (data['UnitPrice'] > 0)]  # Remove rows with negative values\n",
    "\n",
    "# Create a new column for the total price\n",
    "data['TotalPrice'] = data['Quantity'] * data['UnitPrice']\n",
    "\n",
    "# Check the total number of rows after cleaning\n",
    "print(f\"Total rows after cleaning: {data.shape[0]}\")\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed4357e",
   "metadata": {},
   "source": [
    "Calc params for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most recent date\n",
    "current_date = data['InvoiceDate'].max()\n",
    "\n",
    "# RFM\n",
    "rfm = data.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (current_date - x.max()).days,  # Recency\n",
    "    'InvoiceNo': 'count',                                   # Frequency\n",
    "    'TotalPrice': 'sum'                                     # Monetary\n",
    "})\n",
    "\n",
    "# Rename the column\n",
    "rfm.columns = ['Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# 3. Normalizzazione dei dati, non so se serve\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(rfm)\n",
    "\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e641923",
   "metadata": {},
   "source": [
    "Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Elbow Method\n",
    "inertia = []\n",
    "k_range = range(1, 11)  # Number of clusters from 1 to 10\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(rfm_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Elbow plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, inertia, marker='o', label=\"Inertia\")\n",
    "\n",
    "# Highlight the elbow with a red dashed circle\n",
    "optimal_k = 4  # Assuming the elbow is at k=4\n",
    "#circle = plt.Circle((optimal_k, inertia[optimal_k-1]), 0.5, color='red', fill=False, linestyle='--', linewidth=2)\n",
    "#plt.gca().add_artist(circle)\n",
    "\n",
    "# Add the red point for the elbow\n",
    "plt.scatter(optimal_k, inertia[optimal_k-1], color='red', s=100, edgecolors='black', linewidth=2, zorder=5)\n",
    "\n",
    "# Show the inertia value at the elbow point\n",
    "plt.text(optimal_k + 0.1, inertia[optimal_k-1] - 500, f'Inertia: {inertia[optimal_k-1]:,.2f}', fontsize=12)\n",
    "\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Determining Optimal Number of Clusters')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 5. Apply KMeans with the optimal number of clusters (e.g., k=4)\n",
    "kmeans_optimal = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "rfm['Cluster'] = kmeans_optimal.fit_predict(rfm_scaled)\n",
    "\n",
    "# 6. Calculate the percentage of customers in each cluster\n",
    "cluster_counts = rfm['Cluster'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Calculate the absolute number of customers in each cluster\n",
    "cluster_sizes = rfm['Cluster'].value_counts()\n",
    "\n",
    "# Print the number and percentage for each cluster\n",
    "print(\"\\nNumber and percentage of customers in each cluster:\")\n",
    "for cluster in cluster_sizes.index:\n",
    "    percentage = cluster_counts[cluster]\n",
    "    size = cluster_sizes[cluster]\n",
    "    print(f\"Cluster {cluster}: {size} customers ({percentage:.2f}%)\")\n",
    "\n",
    "\n",
    "# 7. 3D Scatter plot based on RFM\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot for each cluster with different colors\n",
    "#colors = ['blue', 'purple', 'yellow', 'orange']  # 4 distinct colors\n",
    "\n",
    "for i, cluster in enumerate(np.unique(rfm['Cluster'])):\n",
    "    ax.scatter(rfm['Recency'][rfm['Cluster'] == cluster], \n",
    "            rfm['Frequency'][rfm['Cluster'] == cluster], \n",
    "            rfm['Monetary'][rfm['Cluster'] == cluster], \n",
    "            c=colors[i], label=f'Cluster {cluster}', s=50, alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Recency')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Monetary')\n",
    "ax.set_title('3D Visualization of Clusters based on RFM')\n",
    "\n",
    "# Add legend\n",
    "ax.legend(title=\"Clusters\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calcolare le medie delle variabili RFM per ciascun cluster\n",
    "cluster_centroids = rfm.groupby('Cluster')[['Recency', 'Frequency', 'Monetary']].mean()\n",
    "print(cluster_centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee148337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate silhouette scores for each point\n",
    "silhouette_values = silhouette_samples(rfm_scaled, kmeans_optimal.labels_)\n",
    "\n",
    "# Calculate the average silhouette score\n",
    "silhouette_avg = np.mean(silhouette_values)\n",
    "print(f\"Average silhouette score: {silhouette_avg:.4f}\")\n",
    "\n",
    "# Create a plot for the silhouette scores for each cluster\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# For each cluster, calculate and plot the silhouette scores\n",
    "y_lower, y_upper = 0, 0\n",
    "for i in range(optimal_k):\n",
    "    # Get the silhouette scores for points in cluster i\n",
    "    cluster_silhouette_values = silhouette_values[kmeans_optimal.labels_ == i]\n",
    "    \n",
    "    # Sort the silhouette scores for cluster i\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    # Calculate the limits for each cluster\n",
    "    y_upper = y_lower + len(cluster_silhouette_values)\n",
    "    \n",
    "    # Plot the silhouette scores for the cluster i\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_values, alpha=0.7, label=f\"Cluster {i}\")\n",
    "    \n",
    "    # Update the lower limit for the next cluster\n",
    "    y_lower = y_upper\n",
    "\n",
    "# Plot a vertical line for the average silhouette score\n",
    "ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", label=f\"Average Silhouette: {silhouette_avg:.4f}\")\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Silhouette Score\")\n",
    "ax.set_ylabel(\"Cluster\")\n",
    "ax.set_title(\"Silhouette Score Distribution for Each Cluster\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85719e05",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neighbors\n",
    "k = 8\n",
    "\n",
    "# Initialize and fit the NearestNeighbors model\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=k)\n",
    "nearest_neighbors.fit(rfm_scaled)\n",
    "\n",
    "# Compute distances and indices of k-nearest neighbors\n",
    "distances, indices = nearest_neighbors.kneighbors(rfm_scaled)\n",
    "\n",
    "# Sort the distances for the k-th nearest neighbor\n",
    "k_distances = np.sort(distances[:, k-1])\n",
    "\n",
    "# Plot the k-distance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_distances, label=\"k-distance\")\n",
    "plt.xlabel(\"Points sorted by distance to 8th nearest neighbor\")\n",
    "plt.ylabel(\"8-distance\")\n",
    "plt.title(\"K-distance Graph for DBSCAN (k = 8)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261dbafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare la distanza media tra i noise points e i 8 più vicini\n",
    "def calculate_noise_distance(rfm_scaled, labels, k=8):\n",
    "    # Trova i punti etichettati come noise (label == -1 in DBSCAN)\n",
    "    noise_points = rfm_scaled[labels == -1]\n",
    "    \n",
    "    if len(noise_points) == 0:\n",
    "        return np.nan  # Se non ci sono outlier, restituisce NaN\n",
    "    \n",
    "    # Calcola le distanze dei punti ai loro k-nearest neighbors\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=k)\n",
    "    nearest_neighbors.fit(rfm_scaled)\n",
    "    distances, _ = nearest_neighbors.kneighbors(noise_points)\n",
    "    \n",
    "    # Calcola la distanza media tra gli outliers e i loro k-nearest neighbors\n",
    "    return np.mean(distances[:, -1])  # La distanza all'8° nearest neighbor\n",
    "\n",
    "# Funzione per testare diverse combinazioni di epsilon e minPts\n",
    "def test_dbscan_combinations(rfm_scaled, epsilon_range, min_pts_range, k=8):\n",
    "    results = []\n",
    "    \n",
    "    # Ciclo su tutte le combinazioni di epsilon e minPts\n",
    "    for epsilon in epsilon_range:\n",
    "        for min_pts in min_pts_range:\n",
    "            # Applica DBSCAN\n",
    "            dbscan = DBSCAN(eps=epsilon, min_samples=min_pts)\n",
    "            labels = dbscan.fit_predict(rfm_scaled)\n",
    "            \n",
    "            # Calcola le metriche\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)  # Escludi il rumore (-1)\n",
    "            silhouette_avg = silhouette_score(rfm_scaled, labels) if n_clusters > 1 else -1  # La silhouette è -1 se ci sono pochi cluster\n",
    "            noise_distance = calculate_noise_distance(rfm_scaled, labels, k)\n",
    "            \n",
    "            # Salva i risultati\n",
    "            results.append({\n",
    "                'epsilon': epsilon,\n",
    "                'min_pts': min_pts,\n",
    "                'n_clusters': n_clusters,\n",
    "                'silhouette_avg': silhouette_avg,\n",
    "                'noise_distance': noise_distance\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Definisci i range per epsilon e minPts\n",
    "epsilon_range = np.linspace(1, 2, 10)  # Epsilon tra 1 e 2 con 10 valori\n",
    "min_pts_range = range(5, 21)  # minPts tra 5 e 20\n",
    "\n",
    "# Testa le combinazioni\n",
    "results_df = test_dbscan_combinations(rfm_scaled, epsilon_range, min_pts_range)\n",
    "\n",
    "# Visualizza i risultati\n",
    "print(results_df)\n",
    "\n",
    "# Se vuoi trovare la combinazione con la migliore silhouette e la distanza media degli outlier\n",
    "best_combination = results_df.loc[results_df['silhouette_avg'].idxmax()]\n",
    "print(\"\\nBest combination based on silhouette score:\")\n",
    "print(best_combination)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#codice provvisorio per fare la heat map ma non viene\n",
    "# Function to calculate the average distance of noise points to their k-nearest neighbors\n",
    "# Funzione per calcolare la distanza media tra i noise points e i 8 più vicini\n",
    "#def calculate_noise_distance(rfm_scaled, labels, k=8):\n",
    "    # Trova i punti etichettati come noise (label == -1 in DBSCAN)\n",
    "#    noise_points = rfm_scaled[labels == -1]\n",
    "    \n",
    "#    if len(noise_points) == 0:\n",
    "#        return np.nan  # Se non ci sono outlier, restituisce NaN\n",
    "    \n",
    "    # Calcola le distanze dei punti ai loro k-nearest neighbors\n",
    "#    nearest_neighbors = NearestNeighbors(n_neighbors=k)\n",
    "#    nearest_neighbors.fit(rfm_scaled)\n",
    "#    distances, _ = nearest_neighbors.kneighbors(noise_points)\n",
    "    \n",
    "    # Calcola la distanza media tra gli outliers e i loro k-nearest neighbors\n",
    "#    return np.mean(distances[:, -1])  # La distanza all'8° nearest neighbor\n",
    "\n",
    "# Funzione per testare diverse combinazioni di epsilon e minPts\n",
    "#def test_dbscan_combinations(rfm_scaled, epsilon_range, min_pts_range, k=8):\n",
    "#    results = []\n",
    "    \n",
    "    # Ciclo su tutte le combinazioni di epsilon e minPts\n",
    "#    for epsilon in epsilon_range:\n",
    "#        for min_pts in min_pts_range:\n",
    "            # Applica DBSCAN\n",
    "#            dbscan = DBSCAN(eps=epsilon, min_samples=min_pts)\n",
    "#            labels = dbscan.fit_predict(rfm_scaled)\n",
    "            \n",
    "            # Calcola le metriche\n",
    "#            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)  # Escludi il rumore (-1)\n",
    "#            silhouette_avg = silhouette_score(rfm_scaled, labels) if n_clusters > 1 else -1  # La silhouette è -1 se ci sono pochi cluster\n",
    "#            noise_distance = calculate_noise_distance(rfm_scaled, labels, k)\n",
    "            \n",
    "            # Salva i risultati\n",
    "#            results.append({\n",
    "#                'epsilon': epsilon,\n",
    "#                'min_pts': min_pts,\n",
    "#                'n_clusters': n_clusters,\n",
    "#                'silhouette_avg': silhouette_avg,\n",
    "#                'noise_distance': noise_distance\n",
    "#            })\n",
    "    \n",
    "#    return pd.DataFrame(results)\n",
    "\n",
    "# Definisci i range per epsilon e minPts\n",
    "#epsilon_range = np.linspace(1, 2, 10)  # Epsilon tra 1 e 2 con 10 valori\n",
    "#min_pts_range = range(5, 21)  # minPts tra 5 e 20\n",
    "\n",
    "# Testa le combinazioni\n",
    "#sns.heatmap(noise_distance_pivot, ax=axes[0], annot=True, fmt=\".2f\", cmap=\"Reds\", cbar_kws={'label': 'Mean Noise Distance'})\n",
    "#axes[0].set_title(\"METRIC: Mean Noise Points Distance\")\n",
    "#axes[0].set_xlabel(\"N\")\n",
    "#axes[0].set_ylabel(\"EPSILON\")\n",
    "\n",
    "# Heatmap: Number of Clusters\n",
    "#sns.heatmap(n_clusters_pivot, ax=axes[1], annot=True, fmt=\"d\", cmap=\"Purples\", cbar_kws={'label': 'Number of Clusters'})\n",
    "#axes[1].set_title(\"METRIC: Number of Clusters\")\n",
    "#axes[1].set_xlabel(\"N\")\n",
    "#axes[1].set_ylabel(\"EPSILON\")\n",
    "\n",
    "# Heatmap: Silhouette Score\n",
    "#sns.heatmap(silhouette_pivot, ax=axes[2], annot=True, fmt=\".2f\", cmap=\"Blues\", cbar_kws={'label': 'Silhouette Score'})\n",
    "#axes[2].set_title(\"METRIC: Silhouette\")\n",
    "#axes[2].set_xlabel(\"N\")\n",
    "#axes[2].set_ylabel(\"EPSILON\")\n",
    "\n",
    "# Save or show the plots\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# Print the best combination based on silhouette score\n",
    "#best_combination = results_df.loc[results_df['silhouette_avg'].idxmax()]\n",
    "#print(\"\\nBest combination based on silhouette score:\")\n",
    "#print(best_combination)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array back to a DataFrame with column names\n",
    "rfm_scaled = pd.DataFrame(rfm_scaled, columns=['Recency', 'Frequency', 'Monetary'])\n",
    "\n",
    "# Apply the DBSCAN algorithm\n",
    "epsilon = 1.888889  # previously determined epsilon value\n",
    "min_pts = 6         # previously determined min_pts value\n",
    "dbscan = DBSCAN(eps=epsilon, min_samples=min_pts)\n",
    "dbscan_labels = dbscan.fit_predict(rfm_scaled)\n",
    "\n",
    "# Add a new column to the DataFrame for cluster labels\n",
    "rfm_scaled['Cluster'] = dbscan_labels\n",
    "\n",
    "# Create the figure for the 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define custom colors: yellow, blue, and red for noise\n",
    "colors = {0: 'blue', 1: 'yellow', -1: 'red'}\n",
    "point_colors = [colors[label] for label in dbscan_labels]\n",
    "\n",
    "# Plot points in 3D space, colored by cluster\n",
    "scatter = ax.scatter(\n",
    "    rfm_scaled['Recency'], rfm_scaled['Frequency'], rfm_scaled['Monetary'],\n",
    "    c=point_colors, marker='o', s=10\n",
    ")\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Recency')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Monetary')\n",
    "\n",
    "# Set the plot title\n",
    "ax.set_title('3D Scatter Plot of RFM Data with DBSCAN Clusters')\n",
    "\n",
    "# Manually create the legend\n",
    "for label, color in colors.items():\n",
    "    if label == -1:\n",
    "        ax.scatter([], [], [], c=color, label='Noise', s=30)  # Red for noise\n",
    "    else:\n",
    "        ax.scatter([], [], [], c=color, label=f'Cluster {label}', s=30)\n",
    "\n",
    "# Add the legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
