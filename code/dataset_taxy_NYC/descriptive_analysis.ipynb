{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for statistical  and time series analysis of the dataset \"NYC Yellow Taxi Trip Data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the required packages, lunch this cell only once (code 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install kagglehub\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install seaborn\n",
    "%pip install folium \n",
    "%pip install scipy\n",
    "%pip install -U jupyter ipywidgets\n",
    "%pip install -U jupyterlab-widgets\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, alpha\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "from datetime import datetime\n",
    "from scipy.stats import probplot"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset and load the data\n",
    "##### lunch this cell only once (code 2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"elemento/nyc-yellow-taxi-trip-data\")\n",
    "# print(\"Path to dataset files:\", path) use only for debug\n",
    "file_path1 = os.path.join(path, \"yellow_tripdata_2015-01.csv\")  # Path to the dataset file\n",
    "file_path2 = os.path.join(path, \"yellow_tripdata_2016-01.csv\")  # Path to the dataset file\n",
    "file_path3 = os.path.join(path, \"yellow_tripdata_2016-02.csv\")  # Path to the dataset file\n",
    "file_path4 = os.path.join(path, \"yellow_tripdata_2016-03.csv\")  # Path to the dataset file"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### there is un error in un colum, so you must run this script for  update and change the column name in first dataset (if you need this column)  (code 3)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def update_and_change(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Update the column name\n",
    "    if 'RateCodeID' in df.columns:\n",
    "        df.rename(columns={'RateCodeID': 'RatecodeID'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_2015_01 = update_and_change(file_path1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Check if database was imported correctly, this script is optional will be used only for debug (code 4)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check if the file exists\n",
    "if os.path.exists(file_path1):\n",
    "    # upload the file to the notebook\n",
    "    df = pd.read_csv(file_path1)\n",
    "\n",
    "    # Print the colum names\n",
    "    print(\"Nomi delle colonne nel dataset:\", df.columns.tolist())\n",
    "else:\n",
    "    print(f\"Il file non esiste. Controlla il percorso: {file_path1}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical analysis in colum VendorID for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Union of the dataset and creation of the bar plot for the frequency of the VendorID (code 5)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1 and 2\n",
    "vendor_colum = ['VendorID']\n",
    "df_2015_01 = pd.read_csv(file_path1, usecols=vendor_colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=vendor_colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=vendor_colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=vendor_colum)    # Load the dataset  in a DataFrame\n",
    "print(\"Number of rows in the dataset 2015-01:\", len(df_2015_01))\n",
    "print(\"Number of rows in the dataset 2016-01:\", len(df_2016_01))\n",
    "print(\"Number of rows in the dataset 2016-02:\", len(df_2016_02))\n",
    "print(\"Number of rows in the dataset 2016-03:\", len(df_2016_03))\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df = pd.concat([df_2015_01, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the bar plot  and pie cacke for the frequency of the VendorID (code 6)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# set a default style \n",
    "plt.style.use('default')\n",
    "\n",
    "# calculate frequenzy of \n",
    "fr_vendor = df['VendorID'].value_counts()\n",
    "\n",
    "# Creazione del grafico a barre con annotazioni e sfondo bianco\n",
    "fig, ax = plt.subplots()\n",
    "fig.patch.set_facecolor('white')  # Impostiamo il colore di sfondo della figura\n",
    "ax.set_facecolor('white')  # Impostiamo il colore di sfondo dell'area del grafico\n",
    "\n",
    "# Creazione del grafico a barre\n",
    "fr_vendor.plot(kind='bar', color=['#1f77b4', '#2ca02c'], ax=ax)\n",
    "\n",
    "# Aggiunta di annotazioni numeriche per ogni barra\n",
    "for i, count in enumerate(fr_vendor):\n",
    "    ax.text(i, count + 5, str(count), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Aggiunta di titolo e etichette\n",
    "ax.set_title(\"Frequency of VendorID\", fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel(\"VendorID\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of trips\", fontsize=12)\n",
    "ax.set_xticks(range(len(fr_vendor.index)))\n",
    "ax.set_xticklabels(fr_vendor.index, rotation=0)\n",
    "\n",
    "# Visualizzazione del grafico a barre\n",
    "plt.show()\n",
    "\n",
    "# Creazione del grafico a torta con percentuali e conteggi, sfondo bianco\n",
    "plt.figure(figsize=(8, 8), facecolor='white')  # Impostiamo il colore di sfondo della figura\n",
    "fr_vendor.plot(kind='pie', \n",
    "               autopct=lambda p: f'{p:.1f}% ({int(p * fr_vendor.sum() / 100)})',  # Percentuali con conteggi\n",
    "               colors=['#1f77b4', '#2ca02c'], \n",
    "               startangle=90, \n",
    "               counterclock=False, \n",
    "               wedgeprops=dict(width=0.3))  # Differenziazione dello stile con spessore\n",
    "\n",
    "# Aggiunta di titolo\n",
    "plt.title(\"Percentage of trips by VendorID\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Visualizzazione del grafico a torta\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the distribution of the trips by hour (code 7)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1 and 2 and 3\n",
    "# union in a single csv only with the column RateCodeID\n",
    "colum_rate = ['RatecodeID'] \n",
    "df_2015_01_filtered = df_2015_01[['RatecodeID']]    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum_rate)    # Load the dataset  in a DataFrame\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum_rate)    # Load the dataset  in a DataFrame\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum_rate)    # Load the dataset  in a DataFrame\n",
    "df=pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the bar plot for the frequency of the RateCodeID (code 8)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Creation of the bar plot for the frequency of the RateCodeID\n",
    "df['Validity_RateCodeID'] = df['RatecodeID'].apply(lambda x: 'valid' if x in range(1, 7) else 'not valid')\n",
    "\n",
    "# Filter the valid RateCodeID\n",
    "ratecode_validi = df[df['Validity_RateCodeID'] == 'valid']['RatecodeID']\n",
    "\n",
    "# Calculate the frequency of the RateCodeID\n",
    "frequent_rate_id = ratecode_validi.value_counts()\n",
    "frequent_rate_id['not valid'] = df['Validity_RateCodeID'].value_counts().get('not valid', 0)\n",
    "\n",
    "# Plot the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = frequent_rate_id.plot(kind='bar', color=['skyblue' if idx != 'not valid' else 'salmon' for idx in frequent_rate_id.index])\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Frequenza dei Codici Tariffari (RatecodeID)\")\n",
    "plt.xlabel(\"RatecodeID\")\n",
    "plt.ylabel(\"Numero di corse\")\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add annotations for each bar\n",
    "for i, count in enumerate(frequent_rate_id):\n",
    "    ax.text(i, count + max(frequent_rate_id) * 0.01, str(count), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Show the bar plot\n",
    "plt.show()\n",
    "\n",
    "# add a pie chart for the % of the RateCodeID\n",
    "plt.figure(figsize=(8, 8), facecolor='white')  \n",
    "frequent_rate_id.plot(kind='pie', \n",
    "                      autopct=lambda p: f'{p:.1f}% ({int(p * frequent_rate_id.sum() / 100)})',\n",
    "                      colors=['skyblue' if idx != 'Non valido' else 'salmon' for idx in frequent_rate_id.index], \n",
    "                      startangle=90, \n",
    "                      counterclock=False, \n",
    "                      wedgeprops=dict(width=0.3))  \n",
    "\n",
    "plt.title(\"Percentuale delle corse per RatecodeID\", fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(frequent_rate_id)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "colum = ['tpep_pickup_datetime'] \n",
    "df_2015_01_filtered = pd.read_csv(file_path1, usecols=colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum)     \n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum)\n",
    "\n",
    "df_total = pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "# convert the column to datetime\n",
    "df_total['tpep_pickup_datetime'] = pd.to_datetime(df_total['tpep_pickup_datetime'])\n",
    "\n",
    "# extract the hour from the datetime\n",
    "df_total['hour'] = df_total['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "#couht the frequency of each hour\n",
    "hour_freq = df_total['hour'].value_counts().sort_index()\n",
    "\n",
    "# create array with the hours\n",
    "hours=hour_freq.index\n",
    "counts=hour_freq.values\n",
    "\n",
    "\n",
    "#print frequency of each hour\n",
    "print(hour_freq)\n",
    "\n",
    "#plot for hour distribution of trips\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=hours, y=counts, color='skyblue')\n",
    "plt.title(\"Distriubution of trips by hour\")\n",
    "plt.xlabel(\"hour\")\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analysis of the distribution of the trips by hour in a day"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "colum = ['tpep_pickup_datetime']  # scelgo la colonna tpep_pickup_datetime\n",
    "df_2015_01_filtered = pd.read_csv(file_path1, usecols=colum)\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum)\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum)\n",
    "\n",
    "df_total = pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "df_total['tpep_pickup_datetime'] = pd.to_datetime(df_total['tpep_pickup_datetime'])\n",
    "\n",
    "df_total['day'] = df_total['tpep_pickup_datetime'].dt.date\n",
    "df_total['hour'] = df_total['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "hourly_day_freq = df_total.groupby(['day', 'hour']).size().reset_index(name='count')\n",
    "\n",
    "avg_hourly_by_day = hourly_day_freq.groupby('hour')['count'].mean().reset_index(name='avg_count')\n",
    "\n",
    "print(avg_hourly_by_day)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=avg_hourly_by_day['hour'], y=avg_hourly_by_day['avg_count'], color='skyblue')\n",
    "plt.title(\"Distribution of trips by hour in a day\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Average number of trips\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.show()\n",
    "unique_days = df_total['day'].unique()\n",
    "\n",
    "unique_days_sorted = np.sort(unique_days)\n",
    "\n",
    "print(\"Giorni trovati nel dataset:\")\n",
    "for day in unique_days_sorted:\n",
    "    print(day)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Try to fit the distribution of the trips by hour with a Gaussian distribution (code 9)\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hour_freq = df_total['hour'].value_counts().sort_index()\n",
    "\n",
    "# 1. Standardizzazione dei dati\n",
    "mean = hour_freq.mean()  # Calculate the mean\n",
    "std = hour_freq.std()    # Deviazione standard for frequency of trips\n",
    "# This process can traform the data for have a media of 0 and a standard deviation of 1\n",
    "\n",
    "\n",
    "hour_freq_standardized = (hour_freq - mean) / std # Standardizzazione of the frequency of trips\n",
    "\n",
    "# 2. Q-Q Plot for check the normality of the data\n",
    "# Q-Q Plot (Quantile-Quantile Plot) compares the quantiles of your observed data (in this case, hour_freq_standardized) with the quantiles of a theoretical normal distribution.\n",
    "# If your data follows a normal distribution:\n",
    "# The Q-Q Plot points line up along the red diagonal line (representing the theoretical values of a standardized normal).\n",
    "# If the data deviate from the diagonal line:\n",
    "# Indicates that the data do not follow a normal distribution.\n",
    "# The further the points are from the diagonal line, the more the data deviate from a normal distribution.\n",
    "plt.figure(figsize=(10, 6))\n",
    "probplot(hour_freq_standardized, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q To check the normality of the data\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean and the standard deviation of the distribution of the trips by hour (code 9)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mu, std = norm.fit(df_total['hour'])\n",
    "\n",
    "# create the gaussian distribution\n",
    "xmin,xmax=0,23\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x,p,'r-', lw=2 ,label='Gaussian fit' ) # Gaussian fit\n",
    "sns.histplot(df_total['hour'], bins=24, color='skyblue', edgecolor='black', stat='density', kde=False,alpha=0.6)\n",
    "#order the x axis and put the center of gayssian distribution in the middle\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.title(\"Distribution of trips by hour\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.show()\n",
    "# plt.legend()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### barplot follow median and standard deviation (code 10)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colum = ['tpep_pickup_datetime'] # scelgo la colonna tpep_pickup_datetime\n",
    "df_2015_01_filtered = pd.read_csv(file_path1, usecols=colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum)     \n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum)\n",
    "\n",
    "df_total = pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "# convert the column to datetime\n",
    "df_total['tpep_pickup_datetime'] = pd.to_datetime(df_total['tpep_pickup_datetime'])\n",
    "\n",
    "# extract the hour from the datetime\n",
    "df_total['hour'] = df_total['tpep_pickup_datetime'].dt.hour\n",
    "#calculate trip for hour\n",
    "hour_freq = df_total['hour'].value_counts().sort_index()\n",
    "#plot for hour distribution of trips\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=hour_freq.index, y=hour_freq.values, color='skyblue')\n",
    "plt.title(\"Distriubution of trips by hour\")\n",
    "plt.xlabel(\"hour\")\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anlaisys on  drip distance (code 11)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1 and 2\n",
    "\n",
    "plt.style.use('default')  \n",
    "sns.set_theme(style=\"white\")  # Set the style of the plots\n",
    "\n",
    "# Load the dataset in a DataFrame\n",
    "columns=['trip_distance']\n",
    "df_2015_01 = pd.read_csv(file_path1, usecols=columns)   # Load the dataset  in a DataFrame  \n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=columns)\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=columns)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=columns)\n",
    "\n",
    "# Filter date with trip distance between 0 and 100 miles\n",
    "df_total = pd.concat([df_2015_01, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "df_total_filtered = df_total[(df_total['trip_distance'] > 0) & (df_total['trip_distance'] <= 30)]\n",
    "\n",
    "# Creare un intervallo personalizzato per i bin\n",
    "custom_bins = np.arange(0, 21, 1)  # Bin da 0 a 20 con intervallo di 1 miglio\n",
    "\n",
    "# Plot the histogram with custom bins\n",
    "plt.figure(figsize=(16, 8))\n",
    "counts, bins, bars = plt.hist(df_total_filtered['trip_distance'], bins=custom_bins, color='skyblue', edgecolor='black', alpha=0.6)\n",
    "\n",
    "# Annotare ogni barra con il numero di viaggi in orientamento verticale\n",
    "for count, bar in zip(counts, bars):\n",
    "    height = bar.get_height()\n",
    "    if height > 0:\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,  # Posizione al centro della barra\n",
    "            height,                             # Posizione in altezza sopra la barra\n",
    "            f'{int(count)}',                    # Testo da visualizzare\n",
    "            ha='center',                        # Allineamento orizzontale\n",
    "            va='bottom',                        # Allineamento verticale\n",
    "            fontsize=10,\n",
    "            rotation=90                         # Rotazione verticale\n",
    "        )\n",
    "\n",
    "# Personalizzare il grafico\n",
    "plt.title(\"Distribuzione delle distanze dei viaggi (fino a 20 miglia) con intervalli di 1 miglio\")\n",
    "plt.xlabel(\"Distanza del viaggio (miglia)\")\n",
    "plt.ylabel(\"Numero di viaggi\")\n",
    "plt.xticks(custom_bins)  # Mostrare tutti i tick corrispondenti ai bin\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Classify trip distances into categories\n",
    "bins = [0,5, 10,15, 20, 30]\n",
    "labels = ['0-5 miglia', '5-10 miglia', '10-15 miglia', '15-20 miglia', '20-30 miglia']\n",
    "df_total_filtered.loc[:, 'Range'] = pd.cut(df_total_filtered['trip_distance'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Calculate the count for each range\n",
    "trip_counts = df_total_filtered['Range'].value_counts()\n",
    "\n",
    "# Create an explode array to emphasize small slices\n",
    "explode = [0.01 if value / trip_counts.sum() < 0.05 else 0 for value in trip_counts]\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    trip_counts, \n",
    "    labels=trip_counts.index, \n",
    "    autopct='%.2f%%', \n",
    "    startangle=140, \n",
    "    colors=sns.color_palette(\"pastel\"),\n",
    "    explode=explode,  # Emphasize small slices\n",
    "    pctdistance=0.85  # Adjust the position of percentage labels\n",
    ")\n",
    "\n",
    "# Improve text readability\n",
    "for text in texts + autotexts:\n",
    "    text.set_fontsize(10)\n",
    "\n",
    "# Add lines connecting labels to small slices\n",
    "plt.title(\"Distribuzione percentuale delle distanze dei viaggi\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the distribution of the trip duration by the hours (code 12)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1, 2  and 3\n",
    "# #unite all dataset in a single csv\n",
    "file_paths=[file_path2, file_path3, file_path4]\n",
    "def load_columns(file_paths, columns_envolved):\n",
    "    df_list = []\n",
    "    for file_path in file_paths:\n",
    "        # load only the columns of interest\n",
    "        df = pd.read_csv(file_path, usecols=columns_envolved)\n",
    "        df_list.append(df)\n",
    "    # unite all the dataframes\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "df_distance = load_columns(file_paths, columns_envolved=['trip_distance'])\n",
    "df_time_fase = load_columns(file_paths, columns_envolved=['trip_distance', 'tpep_pickup_datetime'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3. Cluster the data by the hour\n",
    "\n",
    "df_ratecode_parzial = load_columns(file_paths, columns_envolved=['trip_distance', 'RatecodeID', 'tpep_pickup_datetime'])\n",
    "df_2015_01_filtered = df_2015_01[['trip_distance', 'RatecodeID', 'tpep_pickup_datetime']]    # Load the dataset  in a DataFrame\n",
    "df_ratecode=pd.concat([df_2015_01_filtered, df_ratecode_parzial], ignore_index=True)\n",
    "# convert the column to datetime\n",
    "df_ratecode['tpep_pickup_datetime'] = pd.to_datetime(df_ratecode_parzial['tpep_pickup_datetime'])\n",
    "df_ratecode['pickup_hour'] = df_ratecode['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Calculate the number of trips for each hour\n",
    "trip_for_hour = df_ratecode.groupby('pickup_hour').size()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code 13"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calcolare la distanza media per ora\n",
    "distance_media_for_hour = df_ratecode.groupby('pickup_hour')['trip_distance'].mean()\n",
    "# Creare la figura e il layout per i grafici\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Grafico della distanza media per ora\n",
    "plt.subplot(2, 1, 1)\n",
    "distance_media_for_hour.plot(kind='line', color='orange', marker='o', linestyle='-', linewidth=2, markersize=6)\n",
    "plt.title('Distanza Media per Ora', fontsize=14)\n",
    "plt.xlabel('Ora del Giorno', fontsize=12)\n",
    "plt.ylabel('Distanza Media del Viaggio (miglia)', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "# Impostazioni layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrare il grafico\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crete realtions with ratecode and trip distance (code 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map of the trips (code 15)\n",
    "# exercise with folium"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "columns_needed = [\n",
    "    'tpep_pickup_datetime', 'pickup_longitude', 'pickup_latitude',\n",
    "    'dropoff_longitude', 'dropoff_latitude'\n",
    "]\n",
    "\n",
    "df_2015_01 = pd.read_csv(file_path1, usecols=columns_needed)   # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=columns_needed)\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=columns_needed)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=columns_needed)\n",
    "#concate all the dataframes\n",
    "df= pd.concat([df_2015_01, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "#convert the column to datetime\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# define the period of the day\n",
    "def get_hour_period(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'afternoon'\n",
    "    elif 18 <= hour < 24:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "# create a column for the pickup period\n",
    "df['pickup_period'] = df['tpep_pickup_datetime'].dt.hour.apply(get_hour_period)\n",
    "\n",
    "# Filter the data only for the morning period\n",
    "df = df[(df['pickup_latitude'] != 0) & (df['pickup_longitude'] != 0) &\n",
    "        (df['dropoff_latitude'] != 0) & (df['dropoff_longitude'] != 0)]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create the map centered on New York City\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Add a cluster to group the points\n",
    "marker_cluster = MarkerCluster().add_to(nyc_map)\n",
    "\n",
    "# Group the most frequent routes\n",
    "for period in df['pickup_period'].unique():\n",
    "    period_data = df[df['pickup_period'] == period]\n",
    "    #   Group the most frequent routes\n",
    "    frequent_routes = period_data.groupby(['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']).size().reset_index(name='counts')\n",
    "    top_routes = frequent_routes.nlargest(40, 'counts') \n",
    "    \n",
    "    # Add the routes, the start and end markers on the map\n",
    "    for _, row in top_routes.iterrows():\n",
    "        folium.PolyLine(\n",
    "            locations=[(row['pickup_latitude'], row['pickup_longitude']), (row['dropoff_latitude'], row['dropoff_longitude'])],\n",
    "            color='blue' if period == 'morning' else 'green' if period == 'afternoon' else 'orange' if period == 'evening' else 'purple',\n",
    "            weight=20,\n",
    "            opacity=1  \n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "\n",
    "# Show the map\n",
    "nyc_map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoher tipe of maps (code 16) Clusterizzazione per Tratte"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter only the data for the morning\n",
    "morning_data = df[df['pickup_period'] == 'morning']\n",
    "\n",
    "# create a map centered on New York City\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# add a cluster to group the points\n",
    "marker_cluster = MarkerCluster().add_to(nyc_map)\n",
    "\n",
    "# gruop the most frequent routes\n",
    "frequent_routes = morning_data.groupby(\n",
    "    ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    ").size().reset_index(name='counts')\n",
    "top_routes = frequent_routes.nlargest(40, 'counts')  # Prendiamo le 40 tratte più comuni\n",
    "\n",
    "# add the routes, the start and end markers on the map\n",
    "for _, row in top_routes.iterrows():\n",
    "    # trip\n",
    "    folium.PolyLine(\n",
    "        locations=[\n",
    "            (row['pickup_latitude'], row['pickup_longitude']),\n",
    "            (row['dropoff_latitude'], row['dropoff_longitude'])\n",
    "        ],\n",
    "        color='blue',  # Colore per il tragitto\n",
    "        weight=5,      # Spessore della linea\n",
    "        opacity=0.7    # Opacità per il tragitto\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "    # Marker pickup\n",
    "    folium.Marker(\n",
    "        location=(row['pickup_latitude'], row['pickup_longitude']),\n",
    "        icon=folium.Icon(color='blue', icon='play', prefix='fa'),  # Icona per identificare il punto di partenza\n",
    "        popup='Partenza'\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "    # Marker dropoff\n",
    "    folium.Marker(\n",
    "        location=(row['dropoff_latitude'], row['dropoff_longitude']),\n",
    "        icon=folium.Icon(color='red', icon='flag', prefix='fa'),  # Icona per identificare il punto di arrivo\n",
    "        popup='Arrivo'\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Visualizza la mappa\n",
    "nyc_map\n",
    "# todo: problem whit association of the points"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualizazion ten most pick up e drop off points (code 17)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter only the data for the morning\n",
    "morning_data = df[df['pickup_period'] == 'morning']\n",
    "\n",
    "# Find the 10 most frequent pickup points\n",
    "top_pickups = morning_data.groupby(['pickup_latitude', 'pickup_longitude']).size().reset_index(name='counts')\n",
    "top_pickups = top_pickups.nlargest(10, 'counts').sort_values(by='counts', ascending=False)  # Ordinati per frequenza\n",
    "\n",
    "# Find the 10 most frequent dropoff points\n",
    "top_dropoffs = morning_data.groupby(['dropoff_latitude', 'dropoff_longitude']).size().reset_index(name='counts')\n",
    "top_dropoffs = top_dropoffs.nlargest(10, 'counts').sort_values(by='counts', ascending=False)  # Ordinati per frequenza\n",
    "\n",
    "# Create the map\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Cluster for pickup and dropoff points (is not important in ten most pick up and drop off points)\n",
    "pickup_cluster = MarkerCluster(name='Top 10 Pickup Points - Morning').add_to(nyc_map)\n",
    "dropoff_cluster = MarkerCluster(name='Top 10 Dropoff Points - Morning').add_to(nyc_map)\n",
    "\n",
    "# Add the pickup points with explicit index\n",
    "f=0\n",
    "for index, row in top_pickups.iterrows():\n",
    "    f += 1  # Incrementa f\n",
    "    folium.Marker(\n",
    "        location=(row['pickup_latitude'], row['pickup_longitude']),\n",
    "        icon=folium.Icon(color='blue', icon='play', prefix='fa'),\n",
    "        popup=f'Questo è il numero {f} di punti di partenza (frequenza: {row[\"counts\"]})'  # Indice corretto\n",
    "    ).add_to(pickup_cluster)\n",
    "\n",
    "# Add the dropoff points with explicit index\n",
    "k = 0  \n",
    "for index, row in top_dropoffs.iterrows():\n",
    "    k += 1  # increments k\n",
    "    folium.Marker(\n",
    "        location=(row['dropoff_latitude'], row['dropoff_longitude']),\n",
    "        icon=folium.Icon(color='red', icon='flag', prefix='fa'),\n",
    "        popup=f'Questo è il numero {k} di punti di arrivo (frequenza: {row[\"counts\"]})'  # Indice corretto\n",
    "    ).add_to(dropoff_cluster)\n",
    "\n",
    "# add a layer control\n",
    "folium.LayerControl().add_to(nyc_map)\n",
    "\n",
    "# show the map\n",
    "nyc_map\n",
    "#!!!!!! todo:  problem with the zoom of map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterinf big data visualization (code 17)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter only the data for the morning\n",
    "morning_data = df[df['pickup_period'] == 'morning']\n",
    "\n",
    "# Find the 100 most frequent pickup points\n",
    "top_pickups = morning_data.groupby(['pickup_latitude', 'pickup_longitude']).size().reset_index(name='counts')\n",
    "top_pickups = top_pickups.nlargest(100, 'counts').sort_values(by='counts', ascending=False)  # Ordinati per frequenza\n",
    "\n",
    "# Find the 100 most frequent dropoff points\n",
    "top_dropoffs = morning_data.groupby(['dropoff_latitude', 'dropoff_longitude']).size().reset_index(name='counts')\n",
    "top_dropoffs = top_dropoffs.nlargest(100, 'counts').sort_values(by='counts', ascending=False)  # Ordinati per frequenza\n",
    "\n",
    "# Create the map\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Cluster for pickup and dropoff points\n",
    "pickup_cluster = MarkerCluster(name='Top 10 Pickup Points - Morning').add_to(nyc_map)\n",
    "dropoff_cluster = MarkerCluster(name='Top 10 Dropoff Points - Morning').add_to(nyc_map)\n",
    "\n",
    "# Add the pickup points with explicit index\n",
    "for index, row in top_pickups.iterrows():\n",
    "    folium.Marker(\n",
    "        location=(row['pickup_latitude'], row['pickup_longitude']),\n",
    "        icon=folium.Icon(color='blue', icon='play', prefix='fa'),\n",
    "        popup=f'Punto di partenza #{index + 1} (frequenza: {row[\"counts\"]})'  # Indice corretto\n",
    "    ).add_to(pickup_cluster)\n",
    "\n",
    "# Add the dropoff points with explicit index\n",
    "k = 0 \n",
    "for index, row in top_dropoffs.iterrows():\n",
    "    k += 1  \n",
    "    folium.Marker(\n",
    "        location=(row['dropoff_latitude'], row['dropoff_longitude']),\n",
    "        icon=folium.Icon(color='red', icon='flag', prefix='fa'),\n",
    "        popup=f'Punto di arrivo #{k} (frequenza: {row[\"counts\"]})'  # Indice corretto\n",
    "    ).add_to(dropoff_cluster)\n",
    "\n",
    "# \n",
    "for _, pickup in top_pickups.iterrows():\n",
    "    for _, dropoff in top_dropoffs.iterrows():\n",
    "        # Check if the route is in the morning data\n",
    "        route_data = morning_data[\n",
    "            (morning_data['pickup_latitude'] == pickup['pickup_latitude']) &\n",
    "            (morning_data['pickup_longitude'] == pickup['pickup_longitude']) &\n",
    "            (morning_data['dropoff_latitude'] == dropoff['dropoff_latitude']) &\n",
    "            (morning_data['dropoff_longitude'] == dropoff['dropoff_longitude'])\n",
    "        ]\n",
    "        \n",
    "        if not route_data.empty:\n",
    "            folium.PolyLine(\n",
    "                locations=[(pickup['pickup_latitude'], pickup['pickup_longitude']),\n",
    "                           (dropoff['dropoff_latitude'], dropoff['dropoff_longitude'])],\n",
    "                color='green',\n",
    "                weight=2,\n",
    "                opacity=0.5\n",
    "            ).add_to(nyc_map)\n",
    "\n",
    "# Add a layer control\n",
    "folium.LayerControl().add_to(nyc_map)\n",
    "\n",
    "# Show the map\n",
    "nyc_map\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
