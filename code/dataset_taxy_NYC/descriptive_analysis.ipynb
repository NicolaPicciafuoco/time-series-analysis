{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for statistical  and time series analysis of the dataset \"NYC Yellow Taxi Trip Data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the required packages, lunch this cell only once (code 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install kagglehub\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install seaborn\n",
    "%pip install folium \n",
    "%pip install scipy\n",
    "%pip install -U jupyter ipywidgets\n",
    "%pip install -U jupyterlab-widgets\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, alpha\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset and load the data\n",
    "##### lunch this cell only once (code 2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"elemento/nyc-yellow-taxi-trip-data\")\n",
    "# print(\"Path to dataset files:\", path) use only for debug\n",
    "file_path1 = os.path.join(path, \"yellow_tripdata_2015-01.csv\")  # Path to the dataset file\n",
    "file_path2 = os.path.join(path, \"yellow_tripdata_2016-01.csv\")  # Path to the dataset file\n",
    "file_path3 = os.path.join(path, \"yellow_tripdata_2016-02.csv\")  # Path to the dataset file\n",
    "file_path4 = os.path.join(path, \"yellow_tripdata_2016-03.csv\")  # Path to the dataset file"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### there is un error in un colum, so you must run this script for  update and change the column name in first dataset (if you need this column)  (code 3)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def update_and_change(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Update the column name\n",
    "    if 'RateCodeID' in df.columns:\n",
    "        df.rename(columns={'RateCodeID': 'RatecodeID'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_2015_01 = update_and_change(file_path1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Check if database was imported correctly, this script is optional will be used only for debug (code 4)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check if the file exists\n",
    "if os.path.exists(file_path1):\n",
    "    # upload the file to the notebook\n",
    "    df = pd.read_csv(file_path1)\n",
    "\n",
    "    # Print the colum names\n",
    "    print(\"Nomi delle colonne nel dataset:\", df.columns.tolist())\n",
    "else:\n",
    "    print(f\"Il file non esiste. Controlla il percorso: {file_path1}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical analysis in colum VendorID for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Union of the dataset and creation of the bar plot for the frequency of the VendorID (code 5)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1 and 2\n",
    "vendor_colum = ['VendorID']\n",
    "df_2015_01 = pd.read_csv(file_path1, usecols=vendor_colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=vendor_colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=vendor_colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=vendor_colum)    # Load the dataset  in a DataFrame\n",
    "print(\"Number of rows in the dataset 2015-01:\", len(df_2015_01))\n",
    "print(\"Number of rows in the dataset 2016-01:\", len(df_2016_01))\n",
    "print(\"Number of rows in the dataset 2016-02:\", len(df_2016_02))\n",
    "print(\"Number of rows in the dataset 2016-03:\", len(df_2016_03))\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df = pd.concat([df_2015_01, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the bar plot  and pie cacke for the frequency of the VendorID (code 6)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# set a default style \n",
    "plt.style.use('default')\n",
    "\n",
    "# calculate frequenzy of \n",
    "fr_vendor = df['VendorID'].value_counts()\n",
    "\n",
    "# Creazione del grafico a barre con annotazioni e sfondo bianco\n",
    "fig, ax = plt.subplots()\n",
    "fig.patch.set_facecolor('white')  # Impostiamo il colore di sfondo della figura\n",
    "ax.set_facecolor('white')  # Impostiamo il colore di sfondo dell'area del grafico\n",
    "\n",
    "# Creazione del grafico a barre\n",
    "fr_vendor.plot(kind='bar', color=['#1f77b4', '#2ca02c'], ax=ax)\n",
    "\n",
    "# Aggiunta di annotazioni numeriche per ogni barra\n",
    "for i, count in enumerate(fr_vendor):\n",
    "    ax.text(i, count + 5, str(count), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Aggiunta di titolo e etichette\n",
    "ax.set_title(\"Frequency of VendorID\", fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel(\"VendorID\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of trips\", fontsize=12)\n",
    "ax.set_xticks(range(len(fr_vendor.index)))\n",
    "ax.set_xticklabels(fr_vendor.index, rotation=0)\n",
    "\n",
    "# Visualizzazione del grafico a barre\n",
    "plt.show()\n",
    "\n",
    "# Creazione del grafico a torta con percentuali e conteggi, sfondo bianco\n",
    "plt.figure(figsize=(8, 8), facecolor='white')  # Impostiamo il colore di sfondo della figura\n",
    "fr_vendor.plot(kind='pie', \n",
    "               autopct=lambda p: f'{p:.1f}% ({int(p * fr_vendor.sum() / 100)})',  # Percentuali con conteggi\n",
    "               colors=['#1f77b4', '#2ca02c'], \n",
    "               startangle=90, \n",
    "               counterclock=False, \n",
    "               wedgeprops=dict(width=0.3))  # Differenziazione dello stile con spessore\n",
    "\n",
    "# Aggiunta di titolo\n",
    "plt.title(\"Percentage of trips by VendorID\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Visualizzazione del grafico a torta\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the distribution of the trips by hour (code 7)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1 and 2 and 3\n",
    "# union in a single csv only with the column RateCodeID\n",
    "colum_rate = ['RatecodeID'] \n",
    "df_2015_01_filtered = df_2015_01[['RatecodeID']]    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum_rate)    # Load the dataset  in a DataFrame\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum_rate)    # Load the dataset  in a DataFrame\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum_rate)    # Load the dataset  in a DataFrame\n",
    "df=pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the bar plot for the frequency of the RateCodeID (code 8)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Creation of the bar plot for the frequency of the RateCodeID\n",
    "df['Validity_RateCodeID'] = df['RatecodeID'].apply(lambda x: 'valid' if x in range(1, 7) else 'not valid')\n",
    "\n",
    "# Filter the valid RateCodeID\n",
    "ratecode_validi = df[df['Validity_RateCodeID'] == 'valid']['RatecodeID']\n",
    "\n",
    "# Calculate the frequency of the RateCodeID\n",
    "frequent_rate_id = ratecode_validi.value_counts()\n",
    "frequent_rate_id['not valid'] = df['Validity_RateCodeID'].value_counts().get('not valid', 0)\n",
    "\n",
    "# Plot the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = frequent_rate_id.plot(kind='bar', color=['skyblue' if idx != 'not valid' else 'salmon' for idx in frequent_rate_id.index])\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Frequenza dei Codici Tariffari (RatecodeID)\")\n",
    "plt.xlabel(\"RatecodeID\")\n",
    "plt.ylabel(\"Numero di corse\")\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add annotations for each bar\n",
    "for i, count in enumerate(frequent_rate_id):\n",
    "    ax.text(i, count + max(frequent_rate_id) * 0.01, str(count), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Show the bar plot\n",
    "plt.show()\n",
    "\n",
    "# add a pie chart for the % of the RateCodeID\n",
    "plt.figure(figsize=(8, 8), facecolor='white')  \n",
    "frequent_rate_id.plot(kind='pie', \n",
    "                      autopct=lambda p: f'{p:.1f}% ({int(p * frequent_rate_id.sum() / 100)})',\n",
    "                      colors=['skyblue' if idx != 'Non valido' else 'salmon' for idx in frequent_rate_id.index], \n",
    "                      startangle=90, \n",
    "                      counterclock=False, \n",
    "                      wedgeprops=dict(width=0.3))  \n",
    "\n",
    "plt.title(\"Percentuale delle corse per RatecodeID\", fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(frequent_rate_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import norm, alpha\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "colum = ['tpep_pickup_datetime'] # scelgo la colonna tpep_pickup_datetime\n",
    "df_2015_01_filtered = pd.read_csv(file_path1, usecols=colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum)     \n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum)\n",
    "\n",
    "df_total = pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "# convert the column to datetime\n",
    "df_total['tpep_pickup_datetime'] = pd.to_datetime(df_total['tpep_pickup_datetime'])\n",
    "\n",
    "# extract the hour from the datetime\n",
    "df_total['hour'] = df_total['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# create the gaussian distribution\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# df_total['hour'].hist(bins=24, color='skyblue', edgecolor='black')\n",
    "\n",
    "#couht the frequency of each hour\n",
    "hour_freq = df_total['hour'].value_counts().sort_index()\n",
    "\n",
    "# create array with the hours\n",
    "hours=hour_freq.index\n",
    "counts=hour_freq.values\n",
    "\n",
    "#print frequency of each hour\n",
    "print(hour_freq)\n",
    "\n",
    "#plot for hour distribution of trips\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=hours, y=counts, color='skyblue')\n",
    "plt.title(\"Distriubution of trips by hour\")\n",
    "plt.xlabel(\"hour\")\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.show()\n",
    "# 0     1.691.459\n",
    "# 1     1.246.344\n",
    "# 2      918449\n",
    "# 3      689141\n",
    "# 4      513887\n",
    "# 5      477293\n",
    "# 6     1034368\n",
    "# 7     1756976\n",
    "# 8     2154883\n",
    "# 9     2173883\n",
    "# 10    2107207\n",
    "# 11    2191108\n",
    "# 12    2327988\n",
    "# 13    2325819\n",
    "# 14    2428242\n",
    "# 15    2390529\n",
    "# 16    2.156.376\n",
    "# 17    2.524.604\n",
    "# 18    2.986.286\n",
    "# 19    2.976.744\n",
    "# 20    2.748.153\n",
    "# 21    2.683.741\n",
    "# 22    2.565.133\n",
    "# 23    2.180.232"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Try to fit the distribution of the trips by hour with a Gaussian distribution (code 9)\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import norm, probplot\n",
    "\n",
    "hour_freq_normalized = (hour_freq - hour_freq.mean()) / hour_freq.std()\n",
    "\n",
    "# Q-Q plot to check the normality\n",
    "plt.figure(figsize=(10, 6))\n",
    "probplot(hour_freq_normalized, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot per verificare la normalità\")\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean and the standard deviation of the distribution of the trips by hour (code 9)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "mu, std = norm.fit(df_total['hour'])\n",
    "\n",
    "# create the gaussian distribution\n",
    "xmin,xmax=0,23\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x,p,'r-', lw=2 ,label='Gaussian fit' ) # Gaussian fit\n",
    "sns.histplot(df_total['hour'], bins=24, color='skyblue', edgecolor='black', stat='density', kde=False,alpha=0.6)\n",
    "#order the x axis and put the center of gayssian distribution in the middle\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.title(\"Distribution of trips by hour\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.show()\n",
    "plt.legend()\n",
    "\n",
    "# ha un errore sto codice poi lo vedo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### barplot follow median and standard deviation (code 10)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1 and 2\n",
    "colum = ['tpep_pickup_datetime'] # scelgo la colonna tpep_pickup_datetime\n",
    "df_2015_01_filtered = pd.read_csv(file_path1, usecols=colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum)     \n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum)\n",
    "\n",
    "df_total = pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "# convert the column to datetime\n",
    "df_total['tpep_pickup_datetime'] = pd.to_datetime(df_total['tpep_pickup_datetime'])\n",
    "\n",
    "# extract the hour from the datetime\n",
    "df_total['hour'] = df_total['tpep_pickup_datetime'].dt.hour\n",
    "# Calcola la media e la deviazione standard\n",
    "mu = df_total['hour'].mean()\n",
    "std = df_total['hour'].std()\n",
    "\n",
    "# Definisce i limiti dell'asse x e calcola la distribuzione normale\n",
    "xmin, xmax = 0, 23\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "\n",
    "# Crea il grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, p, 'r-', lw=2, label='Distribuzione Gaussiana')  # Curva gaussiana\n",
    "sns.histplot(df_total['hour'], bins=24, color='skyblue', edgecolor='black', stat='density', kde=False, alpha=0.6)\n",
    "\n",
    "# Aggiunge la media e la deviazione standard al grafico\n",
    "plt.axvline(mu, color='blue', linestyle='--', linewidth=1, label=f'Media: {mu:.2f}')\n",
    "plt.axvline(mu + std, color='green', linestyle='--', linewidth=1, label=f'Media + 1σ: {mu + std:.2f}')\n",
    "plt.axvline(mu - std, color='green', linestyle='--', linewidth=1, label=f'Media - 1σ: {mu - std:.2f}')\n",
    "\n",
    "# Aggiunge titolo e etichette\n",
    "plt.title(\"Distribuzione oraria delle corse dei taxi\")\n",
    "plt.xlabel(\"Ora del giorno\")\n",
    "plt.ylabel(\"Densità (frequenza normalizzata)\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "colum = ['tpep_pickup_datetime'] # scelgo la colonna tpep_pickup_datetime\n",
    "df_2015_01_filtered = pd.read_csv(file_path1, usecols=colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum)     \n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum)\n",
    "\n",
    "df_total = pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "# convert the column to datetime\n",
    "df_total['tpep_pickup_datetime'] = pd.to_datetime(df_total['tpep_pickup_datetime'])\n",
    "\n",
    "# extract the hour from the datetime\n",
    "df_total['hour'] = df_total['tpep_pickup_datetime'].dt.hour\n",
    "# Calcolare la media e la mediana delle ore\n",
    "mu_decimal = df_total['hour'].mean()\n",
    "median_hour = df_total['hour'].median()\n",
    "sigma = df_total['hour'].std()\n",
    "\n",
    "# Convertire la media decimale in formato HH:MM\n",
    "hours = int(mu_decimal)\n",
    "minutes = int((mu_decimal - hours) * 60)\n",
    "\n",
    "# Stampare media e mediana\n",
    "print(f\"La media delle ore è: {hours}:{minutes:02d}\")\n",
    "print(f\"La mediana delle ore è: {int(median_hour)}:00\")\n",
    "\n",
    "# Ordinare i valori per distanza dalla media\n",
    "df_total['distance_from_mean'] = np.abs(df_total['hour'] - mu_decimal)\n",
    "df_sorted = df_total.sort_values('distance_from_mean')\n",
    "\n",
    "# Plot della distribuzione con media e mediana\n",
    "xmin, xmax = 0, 23\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "gaussian_curve = norm.pdf(x, mu_decimal, sigma)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, gaussian_curve, 'r-', lw=2, label='Adattamento Gaussiano')  # Adattamento Gaussiano\n",
    "\n",
    "# Creare l'istogramma con binwidth=1 per ogni ora\n",
    "sns.histplot(df_sorted['hour'], binwidth=1, color='skyblue', edgecolor='black', stat='density', kde=False, alpha=0.6)\n",
    "\n",
    "# Linee per la media, mediana e deviazione standard\n",
    "plt.axvline(mu_decimal, color='red', linestyle='--', label=f'Media ({hours}:{minutes:02d})')\n",
    "plt.axvline(mu_decimal + sigma, color='green', linestyle='--', label='Media + 1σ')\n",
    "plt.axvline(mu_decimal - sigma, color='green', linestyle='--', label='Media - 1σ')\n",
    "\n",
    "# Titoli e legende\n",
    "plt.title(\"Distribuzione delle corse per ora con Media e Mediana\")\n",
    "plt.xlabel(\"Ora\")\n",
    "plt.ylabel(\"Densità\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.xlim(xmin, xmax)  # Imposta il limite dell'asse x per centrarlo correttamente\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualizzazione outliers con boxplot\n",
    "plt.figure(figsize=(10, 2))\n",
    "sns.boxplot(x=df_total['hour'], color='skyblue')\n",
    "plt.title(\"Distribuzione dei valori di Hour con Outliers\")\n",
    "plt.xlabel(\"Ora\")\n",
    "plt.xlim(xmin, xmax)  # Imposta il limite dell'asse x per centrarlo correttamente nel boxplot\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colum = ['tpep_pickup_datetime'] # scelgo la colonna tpep_pickup_datetime\n",
    "df_2015_01_filtered = pd.read_csv(file_path1, usecols=colum)    # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=colum)     \n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=colum)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=colum)\n",
    "\n",
    "df_total = pd.concat([df_2015_01_filtered, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "# convert the column to datetime\n",
    "df_total['tpep_pickup_datetime'] = pd.to_datetime(df_total['tpep_pickup_datetime'])\n",
    "\n",
    "# extract the hour from the datetime\n",
    "df_total['hour'] = df_total['tpep_pickup_datetime'].dt.hour\n",
    "#calculate trip for hour\n",
    "hour_freq = df_total['hour'].value_counts().sort_index()\n",
    "#plot for hour distribution of trips\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=hour_freq.index, y=hour_freq.values, color='skyblue')\n",
    "plt.title(\"Distriubution of trips by hour\")\n",
    "plt.xlabel(\"hour\")\n",
    "plt.ylabel(\"Number of trips\")\n",
    "plt.xticks(np.arange(0, 24, 1))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anlaisys on  drip distance (code 11)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1 and 2\n",
    "\n",
    "plt.style.use('default')  \n",
    "sns.set_theme(style=\"white\")  # Set the style of the plots\n",
    "\n",
    "# Load the dataset in a DataFrame\n",
    "columns=['trip_distance']\n",
    "df_2015_01 = pd.read_csv(file_path1, usecols=columns)   # Load the dataset  in a DataFrame  \n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=columns)\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=columns)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=columns)\n",
    "\n",
    "# Filter date with trip distance between 0 and 100 miles\n",
    "df_total = pd.concat([df_2015_01, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "df_total_filtered = df_total[(df_total['trip_distance'] > 0) & (df_total['trip_distance'] <= 40)]\n",
    "\n",
    "# Calculate the mean and standard deviation of the distribution\n",
    "mu, std = norm.fit(df_total_filtered['trip_distance'])\n",
    "\n",
    "# Create the Gaussian distribution\n",
    "x = np.linspace(0, 40, 80)\n",
    "p = norm.pdf(x, mu, std)        # Gaussian distribution\n",
    "\n",
    "# Plot the histogram and the Gaussian distribution\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.histplot(df_total_filtered['trip_distance'], bins=40, color='skyblue', edgecolor='black', stat='density', kde=False, alpha=0.6)\n",
    "plt.plot(x, p, 'r-', lw=2, label=f'Gaussian fit (μ={mu:.2f}, σ={std:.2f})')  # Curve of the Gaussian distribution\n",
    "plt.title(\"Distribuzione delle distanze dei viaggi (fino a 20 miglia)\")\n",
    "plt.xlabel(\"Distanza del viaggio (miglia)\")\n",
    "plt.ylabel(\"Densità\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the distribution of the trip duration by the hours (code 12)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1, 2  and 3\n",
    "# #unite all dataset in a single csv\n",
    "file_paths=[file_path2, file_path3, file_path4]\n",
    "def load_columns(file_paths, columns_envolved):\n",
    "    df_list = []\n",
    "    for file_path in file_paths:\n",
    "        # load only the columns of interest\n",
    "        df = pd.read_csv(file_path, usecols=columns_envolved)\n",
    "        # correct the name of the column RateCodeID\n",
    "        # df = df[df['RatecodeID'].isin([1, 6])]\n",
    "        if 'RateCodeID' in df.columns:\n",
    "            df.rename(columns={'RateCodeID': 'RatecodeID'}, inplace=True)\n",
    "        df_list.append(df)\n",
    "    # unite all the dataframes\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "df_distance = load_columns(file_paths, columns_envolved=['trip_distance'])\n",
    "df_time_fase = load_columns(file_paths, columns_envolved=['trip_distance', 'tpep_pickup_datetime'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3. Cluster the data by the hour\n",
    "#df_ratecode_parzial = load_colums(file_paths, colums_envolved=['trip_distance', 'RatecodeID'])\n",
    "#filter ratecodeID between 0 and 6\n",
    "\n",
    "df_ratecode_parzial = load_columns(file_paths, columns_envolved=['trip_distance', 'RatecodeID', 'tpep_pickup_datetime'])\n",
    "df_2015_01_filtered = df_2015_01[['trip_distance', 'RatecodeID', 'tpep_pickup_datetime']]    # Load the dataset  in a DataFrame\n",
    "df_ratecode=pd.concat([df_2015_01_filtered, df_ratecode_parzial], ignore_index=True)\n",
    "# convert the column to datetime\n",
    "df_ratecode['tpep_pickup_datetime'] = pd.to_datetime(df_ratecode_parzial['tpep_pickup_datetime'])\n",
    "df_ratecode['pickup_hour'] = df_ratecode['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Calculate the number of trips for each hour\n",
    "trip_for_hour = df_ratecode.groupby('pickup_hour').size()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code 13"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#! before run this you must run the code 1, 2 ,3 and 12\n",
    "\n",
    "distance_media_for_hour = df_ratecode.groupby('pickup_hour')['trip_distance'].mean()\n",
    "\n",
    "# Plot the number of trips and the average distance for each hour\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Number of trips for each hour\n",
    "plt.subplot(2, 1, 1)\n",
    "trip_for_hour.plot(kind='bar', color='skyblue')\n",
    "plt.title('Numero di Viaggi per Ora')\n",
    "plt.xlabel('Ora del Giorno')\n",
    "plt.ylabel('Numero di Viaggi')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Distance for each hour\n",
    "plt.subplot(2, 1, 2)\n",
    "distance_media_for_hour.plot(kind='line', marker='o', color='orange')\n",
    "plt.title('Distanza Media per Ora')\n",
    "plt.xlabel('Ora del Giorno')\n",
    "plt.ylabel('Distanza Media del Viaggio')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crete realtions with ratecode and trip distance (code 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map of the trips (code 15)\n",
    "# exercise with folium"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "columns_needed = [\n",
    "    'tpep_pickup_datetime', 'pickup_longitude', 'pickup_latitude',\n",
    "    'dropoff_longitude', 'dropoff_latitude'\n",
    "]\n",
    "\n",
    "df_2015_01 = pd.read_csv(file_path1, usecols=columns_needed)   # Load the dataset  in a DataFrame\n",
    "df_2016_01 = pd.read_csv(file_path2, usecols=columns_needed)\n",
    "df_2016_02 = pd.read_csv(file_path3, usecols=columns_needed)\n",
    "df_2016_03 = pd.read_csv(file_path4, usecols=columns_needed)\n",
    "#concate all the dataframes\n",
    "df= pd.concat([df_2015_01, df_2016_01, df_2016_02, df_2016_03], ignore_index=True)\n",
    "\n",
    "#convert the column to datetime\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# define the period of the day\n",
    "def get_hour_period(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'afternoon'\n",
    "    elif 18 <= hour < 24:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "# create a column for the pickup period\n",
    "df['pickup_period'] = df['tpep_pickup_datetime'].dt.hour.apply(get_hour_period)\n",
    "\n",
    "# Filter the data only for the morning period\n",
    "df = df[(df['pickup_latitude'] != 0) & (df['pickup_longitude'] != 0) &\n",
    "        (df['dropoff_latitude'] != 0) & (df['dropoff_longitude'] != 0)]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create the map centered on New York City\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Add a cluster to group the points\n",
    "marker_cluster = MarkerCluster().add_to(nyc_map)\n",
    "\n",
    "# Group the most frequent routes\n",
    "for period in df['pickup_period'].unique():\n",
    "    period_data = df[df['pickup_period'] == period]\n",
    "    #   Group the most frequent routes\n",
    "    frequent_routes = period_data.groupby(['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']).size().reset_index(name='counts')\n",
    "    top_routes = frequent_routes.nlargest(40, 'counts') \n",
    "    \n",
    "    # Add the routes, the start and end markers on the map\n",
    "    for _, row in top_routes.iterrows():\n",
    "        folium.PolyLine(\n",
    "            locations=[(row['pickup_latitude'], row['pickup_longitude']), (row['dropoff_latitude'], row['dropoff_longitude'])],\n",
    "            color='blue' if period == 'morning' else 'green' if period == 'afternoon' else 'orange' if period == 'evening' else 'purple',\n",
    "            weight=20,\n",
    "            opacity=1  \n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "\n",
    "# Show the map\n",
    "nyc_map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoher tipe of maps (code 16) Clusterizzazione per Tratte"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter only the data for the morning\n",
    "morning_data = df[df['pickup_period'] == 'morning']\n",
    "\n",
    "# create a map centered on New York City\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# add a cluster to group the points\n",
    "marker_cluster = MarkerCluster().add_to(nyc_map)\n",
    "\n",
    "# gruop the most frequent routes\n",
    "frequent_routes = morning_data.groupby(\n",
    "    ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    ").size().reset_index(name='counts')\n",
    "top_routes = frequent_routes.nlargest(40, 'counts')  # Prendiamo le 40 tratte più comuni\n",
    "\n",
    "# add the routes, the start and end markers on the map\n",
    "for _, row in top_routes.iterrows():\n",
    "    # trip\n",
    "    folium.PolyLine(\n",
    "        locations=[\n",
    "            (row['pickup_latitude'], row['pickup_longitude']),\n",
    "            (row['dropoff_latitude'], row['dropoff_longitude'])\n",
    "        ],\n",
    "        color='blue',  # Colore per il tragitto\n",
    "        weight=5,      # Spessore della linea\n",
    "        opacity=0.7    # Opacità per il tragitto\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "    # Marker pickup\n",
    "    folium.Marker(\n",
    "        location=(row['pickup_latitude'], row['pickup_longitude']),\n",
    "        icon=folium.Icon(color='blue', icon='play', prefix='fa'),  # Icona per identificare il punto di partenza\n",
    "        popup='Partenza'\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "    # Marker dropoff\n",
    "    folium.Marker(\n",
    "        location=(row['dropoff_latitude'], row['dropoff_longitude']),\n",
    "        icon=folium.Icon(color='red', icon='flag', prefix='fa'),  # Icona per identificare il punto di arrivo\n",
    "        popup='Arrivo'\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Visualizza la mappa\n",
    "nyc_map\n",
    "# todo: problem whit association of the points"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualizazion ten most pick up e drop off points (code 17)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter only the data for the morning\n",
    "morning_data = df[df['pickup_period'] == 'morning']\n",
    "\n",
    "# Find the 10 most frequent pickup points\n",
    "top_pickups = morning_data.groupby(['pickup_latitude', 'pickup_longitude']).size().reset_index(name='counts')\n",
    "top_pickups = top_pickups.nlargest(10, 'counts').sort_values(by='counts', ascending=False)  # Ordinati per frequenza\n",
    "\n",
    "# Find the 10 most frequent dropoff points\n",
    "top_dropoffs = morning_data.groupby(['dropoff_latitude', 'dropoff_longitude']).size().reset_index(name='counts')\n",
    "top_dropoffs = top_dropoffs.nlargest(10, 'counts').sort_values(by='counts', ascending=False)  # Ordinati per frequenza\n",
    "\n",
    "# Create the map\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Cluster for pickup and dropoff points (is not important in ten most pick up and drop off points)\n",
    "pickup_cluster = MarkerCluster(name='Top 10 Pickup Points - Morning').add_to(nyc_map)\n",
    "dropoff_cluster = MarkerCluster(name='Top 10 Dropoff Points - Morning').add_to(nyc_map)\n",
    "\n",
    "# Add the pickup points with explicit index\n",
    "f=0\n",
    "for index, row in top_pickups.iterrows():\n",
    "    f += 1  # Incrementa f\n",
    "    folium.Marker(\n",
    "        location=(row['pickup_latitude'], row['pickup_longitude']),\n",
    "        icon=folium.Icon(color='blue', icon='play', prefix='fa'),\n",
    "        popup=f'Questo è il numero {f} di punti di partenza (frequenza: {row[\"counts\"]})'  # Indice corretto\n",
    "    ).add_to(pickup_cluster)\n",
    "\n",
    "# Add the dropoff points with explicit index\n",
    "k = 0  \n",
    "for index, row in top_dropoffs.iterrows():\n",
    "    k += 1  # increments k\n",
    "    folium.Marker(\n",
    "        location=(row['dropoff_latitude'], row['dropoff_longitude']),\n",
    "        icon=folium.Icon(color='red', icon='flag', prefix='fa'),\n",
    "        popup=f'Questo è il numero {k} di punti di arrivo (frequenza: {row[\"counts\"]})'  # Indice corretto\n",
    "    ).add_to(dropoff_cluster)\n",
    "\n",
    "# add a layer control\n",
    "folium.LayerControl().add_to(nyc_map)\n",
    "\n",
    "# show the map\n",
    "nyc_map\n",
    "#!!!!!! todo:  problem with the zoom of map"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterinf big data visualization (code 17)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter only the data for the morning\n",
    "morning_data = df[df['pickup_period'] == 'morning']\n",
    "\n",
    "# Find the 100 most frequent pickup points\n",
    "top_pickups = morning_data.groupby(['pickup_latitude', 'pickup_longitude']).size().reset_index(name='counts')\n",
    "top_pickups = top_pickups.nlargest(100, 'counts').sort_values(by='counts', ascending=False)  # Ordinati per frequenza\n",
    "\n",
    "# Find the 100 most frequent dropoff points\n",
    "top_dropoffs = morning_data.groupby(['dropoff_latitude', 'dropoff_longitude']).size().reset_index(name='counts')\n",
    "top_dropoffs = top_dropoffs.nlargest(100, 'counts').sort_values(by='counts', ascending=False)  # Ordinati per frequenza\n",
    "\n",
    "# Create the map\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "\n",
    "# Cluster for pickup and dropoff points\n",
    "pickup_cluster = MarkerCluster(name='Top 10 Pickup Points - Morning').add_to(nyc_map)\n",
    "dropoff_cluster = MarkerCluster(name='Top 10 Dropoff Points - Morning').add_to(nyc_map)\n",
    "\n",
    "# Add the pickup points with explicit index\n",
    "for index, row in top_pickups.iterrows():\n",
    "    folium.Marker(\n",
    "        location=(row['pickup_latitude'], row['pickup_longitude']),\n",
    "        icon=folium.Icon(color='blue', icon='play', prefix='fa'),\n",
    "        popup=f'Punto di partenza #{index + 1} (frequenza: {row[\"counts\"]})'  # Indice corretto\n",
    "    ).add_to(pickup_cluster)\n",
    "\n",
    "# Add the dropoff points with explicit index\n",
    "k = 0 \n",
    "for index, row in top_dropoffs.iterrows():\n",
    "    k += 1  \n",
    "    folium.Marker(\n",
    "        location=(row['dropoff_latitude'], row['dropoff_longitude']),\n",
    "        icon=folium.Icon(color='red', icon='flag', prefix='fa'),\n",
    "        popup=f'Punto di arrivo #{k} (frequenza: {row[\"counts\"]})'  # Indice corretto\n",
    "    ).add_to(dropoff_cluster)\n",
    "\n",
    "# \n",
    "for _, pickup in top_pickups.iterrows():\n",
    "    for _, dropoff in top_dropoffs.iterrows():\n",
    "        # Check if the route is in the morning data\n",
    "        route_data = morning_data[\n",
    "            (morning_data['pickup_latitude'] == pickup['pickup_latitude']) &\n",
    "            (morning_data['pickup_longitude'] == pickup['pickup_longitude']) &\n",
    "            (morning_data['dropoff_latitude'] == dropoff['dropoff_latitude']) &\n",
    "            (morning_data['dropoff_longitude'] == dropoff['dropoff_longitude'])\n",
    "        ]\n",
    "        \n",
    "        if not route_data.empty:\n",
    "            folium.PolyLine(\n",
    "                locations=[(pickup['pickup_latitude'], pickup['pickup_longitude']),\n",
    "                           (dropoff['dropoff_latitude'], dropoff['dropoff_longitude'])],\n",
    "                color='green',\n",
    "                weight=2,\n",
    "                opacity=0.5\n",
    "            ).add_to(nyc_map)\n",
    "\n",
    "# Add a layer control\n",
    "folium.LayerControl().add_to(nyc_map)\n",
    "\n",
    "# Show the map\n",
    "nyc_map\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
